const WS_UPLOAD_URL = import.meta.env.VITE_WS_UPLOAD_URL;
const WS_TEXT_URL   = import.meta.env.VITE_WS_TEXT_URL;
const WS_TTS_URL    = import.meta.env.VITE_WS_TTS_URL;

export function createStreamClient({
  conversationId,
  model = "free",
  accent = "American English",
  onText,
  onTtsStart,
  onTtsBlob,
  onTtsEnded,
  outputVolume = 1,
}) {
  let uploadWS = null;
  let textWS = null;
  let ttsWS = null;

  let mediaStream = null;
  let mediaRecorder = null;

  // ===== TTS æ’­æ”¾ç›¸å…³ =====
  let ttsMime = "audio/mpeg";
  let ttsChunks = []; // æ”¶é›†æ‰€æœ‰äºŒè¿›åˆ¶åˆ†ç‰‡ï¼Œæœ€åæ‹¼æˆ Blob

  // -- MSE æ’­æ”¾å™¨ --
  let audioEl = null;
  let mediaSource = null;
  let sourceBuffer = null;
  let mseQueue = [];         // Uint8Array é˜Ÿåˆ—ï¼Œç­‰å¾… append
  let mseReady = false;
  let mseEnded = false;

  // -- WebAudio é€€åŒ–æ’­æ”¾å™¨ï¼ˆä»…åœ¨ MSE ä¸å¯ç”¨æ—¶å¯ç”¨ï¼‰ --
  let audioContext = null;
  let decodeQueue = [];      // ArrayBuffer é˜Ÿåˆ—
  let decodePlaying = false;

  let currentVolume = Math.max(0, Math.min(1, outputVolume));

  // ========== å·¥å…· ==========
  function sendJSON(ws, obj) {
    if (ws && ws.readyState === WebSocket.OPEN) ws.send(JSON.stringify(obj));
  }

  function ensureAudioElement() {
    if (audioEl) return audioEl;
    audioEl = document.createElement("audio");
    audioEl.autoplay = true;
    audioEl.controls = false;
    audioEl.style.display = "none"; // ä¸å ä½
    audioEl.volume = currentVolume;
    document.body.appendChild(audioEl);
    return audioEl;
  }

  // ========== MSE å®ç° ==========
  function mseInit() {
    const el = ensureAudioElement();
    if (!("MediaSource" in window)) return false;

    mediaSource = new MediaSource();
    el.src = URL.createObjectURL(mediaSource);
    mseQueue = [];
    mseReady = false;
    mseEnded = false;

    mediaSource.addEventListener("sourceopen", () => {
      try {
        // ç»å¤§å¤šæ•°æµè§ˆå™¨æ”¯æŒ 'audio/mpeg'
        if (!MediaSource.isTypeSupported(ttsMime)) {
          // é€€åŒ–ä¸º audio/mpeg
          ttsMime = "audio/mpeg";
        }
        sourceBuffer = mediaSource.addSourceBuffer(ttsMime);
        sourceBuffer.mode = "sequence";
        sourceBuffer.addEventListener("updateend", mseFeed);
        mseReady = true;
        mseFeed();
      } catch (e) {
        console.warn("[MSE] sourceopen error, fallback to WebAudio:", e);
        mseTearDown();
      }
    });

    mediaSource.addEventListener("error", (e) => {
      console.warn("[MSE] mediaSource error:", e);
    });

    return true;
  }

  function mseAppend(u8) {
    if (!mseReady || !sourceBuffer) {
      mseQueue.push(u8);
      return;
    }
    mseQueue.push(u8);
    mseFeed();
  }

  function mseFeed() {
    if (!sourceBuffer || sourceBuffer.updating) return;
    if (mseQueue.length === 0) {
      if (mseEnded && mediaSource && mediaSource.readyState === "open") {
        try { mediaSource.endOfStream(); } catch {}
      }
      return;
    }
    const chunk = mseQueue.shift();
    try {
      sourceBuffer.appendBuffer(chunk);
    } catch (e) {
      console.warn("[MSE] append error, dropping chunk:", e);
    }
  }

  function mseEnd() {
    mseEnded = true;
    mseFeed();
  }

  function mseTearDown() {
    try {
      if (sourceBuffer) {
        sourceBuffer.abort();
      }
    } catch {}
    try {
      if (mediaSource && mediaSource.readyState === "open") {
        mediaSource.endOfStream();
      }
    } catch {}
    sourceBuffer = null;
    mediaSource = null;
    mseQueue = [];
    mseReady = false;
    mseEnded = false;
  }

  // ========== WebAudio é€€åŒ–å®ç°ï¼ˆæ”’åŒ…åè§£ç ï¼‰ ==========
  const MIN_CHUNK_BYTES = 24 * 1024; // ç´¯è®¡åˆ° 24KB å†è§£ç 
  const MAX_BUFFER_BYTES = 1024 * 1024; // ä¸Šé™ 1MB

  async function waPlayNext() {
    if (decodePlaying) return;
    decodePlaying = true;

    try {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
      }
      const el = ensureAudioElement(); // ç”¨ <audio> æ§åˆ¶éŸ³é‡çš„è§†è§‰è¡Œä¸ºï¼Œè¿™é‡Œä¸ç”¨å…¶è§£ç 
      el.volume = currentVolume;

      while (decodeQueue.length > 0) {
        // æ‹¼æ¥å°½å¯èƒ½å¤šçš„åˆ†ç‰‡ï¼Œæé«˜è§£ç æˆåŠŸç‡
        let total = 0;
        for (const ab of decodeQueue) total += ab.byteLength;
        if (total < MIN_CHUNK_BYTES) break;

        // å–å°½é‡å¤šçš„æ•°æ®å»è§£ç 
        const big = new Uint8Array(total);
        let offset = 0;
        while (decodeQueue.length) {
          const ab = decodeQueue.shift();
          const u8 = new Uint8Array(ab);
          big.set(u8, offset);
          offset += u8.byteLength;
        }

        try {
          const buf = big.buffer;
          const decoded = await audioContext.decodeAudioData(buf.slice(0));
          const src = audioContext.createBufferSource();
          const gain = audioContext.createGain();
          gain.gain.value = currentVolume;
          src.buffer = decoded;
          src.connect(gain);
          gain.connect(audioContext.destination);

          await new Promise((resolve) => {
            src.onended = resolve;
            src.start(0);
          });
        } catch (e) {
          console.warn("[WebAudio] decode failed once, keep buffering:", e);
          // æ”¾å›å»ï¼Œç­‰å¾…æ›´å¤šæ•°æ®
          decodeQueue.unshift(big.buffer);
          if (big.byteLength > MAX_BUFFER_BYTES) {
            console.warn("[WebAudio] buffer too large, dropping");
            decodeQueue = [];
          }
          break;
        }
      }
    } finally {
      decodePlaying = false;
    }
  }

  // ========== å¤–éƒ¨ API ==========
  async function open() {
    console.log("[client] createStreamClient.open() called");

    // 1) æ–‡æœ¬é€šé“
    await new Promise((resolve, reject) => {
      textWS = new WebSocket(WS_TEXT_URL);
      textWS.onopen = () => {
        console.log("[client] textWS open, subscribe", conversationId);
        sendJSON(textWS, { type: "subscribe", conversationId });
        resolve();
      };
      textWS.onerror = (e) => { console.error("[client] textWS error", e); reject(e); };
      textWS.onmessage = (ev) => {
        try {
          const msg = JSON.parse(ev.data);
          if (msg?.type === "ready" || msg?.type === "pong") return;
          if (msg.type === "interim") {
            onText?.({ interim: msg.text, ts: msg.ts, confidence: msg.confidence });
          } else if (msg.type === "final") {
            onText?.({ final: msg.text, ts: msg.ts, confidence: msg.confidence });
          } else {
            console.warn("[client] textWS unknown msg:", msg);
          }
        } catch {
          if (typeof ev.data === "string") onText?.(ev.data);
        }
      };
    });

    // 2) TTS é€šé“
    if (WS_TTS_URL) {
      try {
        await new Promise((resolve, reject) => {
          ttsWS = new WebSocket(WS_TTS_URL);
          ttsWS.binaryType = "arraybuffer";

          ttsWS.onopen = () => {
            console.log("[client] ttsWS open, subscribe", conversationId);
            sendJSON(ttsWS, { type: "start", conversationId });
            resolve();
          };

          ttsWS.onerror = (e) => { console.warn("[client] ttsWS error", e); reject(e); };

          ttsWS.onmessage = (ev) => {
            if (typeof ev.data === "string") {
              // æ§åˆ¶æ¶ˆæ¯
              try {
                const msg = JSON.parse(ev.data);
                if (msg.type === "start") {
                  console.log("[client] ğŸµ TTS stream starting");
                  ttsMime = msg.mime || "audio/mpeg";
                  ttsChunks = [];

                  // ä¼˜å…ˆä½¿ç”¨ MSEï¼Œå¤±è´¥åˆ™é€€åŒ–åˆ° WebAudio
                  const ok = mseInit();
                  if (!ok) {
                    console.warn("[client] MSE not available, fallback to WebAudio buffering");
                    // æ¸…ç† WebAudio é˜Ÿåˆ—
                    decodeQueue = [];
                    decodePlaying = false;
                  }
                  onTtsStart?.();
                } else if (msg.type === "stop") {
                  console.log("[client] ğŸµ TTS stream stopped");
                  // å®Œæˆ MSE
                  if (mediaSource) mseEnd();

                  // ç­‰å¾…æ’­æ”¾å‡ ç™¾æ¯«ç§’å†å‡º blobï¼ˆä¿é™©ï¼‰
                  setTimeout(() => {
                    const blob = new Blob(ttsChunks, { type: ttsMime });
                    onTtsBlob?.(blob);
                    onTtsEnded?.();
                  }, 300);
                }
              } catch {
                // ignore é JSON æ–‡æœ¬
              }
            } else if (ev.data instanceof ArrayBuffer) {
              // äºŒè¿›åˆ¶åˆ†ç‰‡
              const ab = ev.data.slice(0);
              const u8 = new Uint8Array(ab);
              ttsChunks.push(u8);

              // MSE è·¯å¾„
              if (mediaSource && sourceBuffer) {
                mseAppend(u8);
              } else {
                // é€€åŒ–è·¯å¾„ï¼šç¼“å†²åˆ°ä¸€å®šå¤§å°å†è§£ç 
                decodeQueue.push(ab);
                if (!decodePlaying) waPlayNext();
              }
            }
          };
        });
      } catch (e) {
        console.error("[client] ttsWS connection failed:", e);
        ttsWS = null;
      }
    }

    // 3) ä¸Šä¼ é€šé“
    await new Promise((resolve, reject) => {
      uploadWS = new WebSocket(WS_UPLOAD_URL);
      uploadWS.onopen = () => {
        console.log("[client] uploadWS open");
        sendJSON(uploadWS, {
          type: "start",
          conversationId,
          model,
          accent,
          sampleRate: 48000,
          format: "audio/webm;codecs=opus",
          asrProvider: "whisper",
        });
        resolve();
      };
      uploadWS.onerror = (e) => { console.error("[client] uploadWS error", e); reject(e); };
    });
  }

  async function startSegment() {
    // noop
  }

  async function stopSegment() {
    if (uploadWS?.readyState === WebSocket.OPEN) {
      console.log("[client] send stop");
      sendJSON(uploadWS, { type: "stop" });
    }
  }

  async function startMic() {
    console.log("[client] requesting mic");
    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("[client] mic granted");
    } catch (e) {
      console.error("[client] getUserMedia failed:", e.name, e.message);
      throw e;
    }

    const mime = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
      ? "audio/webm;codecs=opus"
      : "audio/webm";

    mediaRecorder = new MediaRecorder(mediaStream, {
      mimeType: mime,
      audioBitsPerSecond: 128000,
    });

    mediaRecorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0 && uploadWS?.readyState === WebSocket.OPEN) {
        e.data.arrayBuffer().then((buf) => uploadWS.send(buf));
      }
    };

    mediaRecorder.start(40);
  }

  async function stopMic() {
    try { mediaRecorder?.stop(); } catch {}
    mediaStream?.getTracks().forEach((t) => t.stop());
    mediaRecorder = null;
    mediaStream = null;
  }

  async function close() {
    try { textWS?.close(); } catch {}
    try { ttsWS?.close(); } catch {}
    try { uploadWS?.close(); } catch {}

    // é‡Šæ”¾ MSE
    try { mseTearDown(); } catch {}

    // é‡Šæ”¾ WebAudio
    if (audioContext) {
      try { await audioContext.close(); } catch {}
      audioContext = null;
    }
  }

  function setOutputVolume(v) {
    currentVolume = Math.max(0, Math.min(1, v));
    if (audioEl) audioEl.volume = currentVolume;
    // WebAudio é€€åŒ–è·¯å¾„ä¸‹ä¹Ÿä¼šåœ¨æ’­æ”¾æ—¶è¯»å– currentVolume
    console.log("[streamClient] Volume set to:", currentVolume);
  }

  return { open, startSegment, stopSegment, startMic, stopMic, close, setOutputVolume };
}
